{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lambda Execution Log Analysis\n",
    "\n",
    "Analysis of Lambda execution logs from S3.\n",
    "\n",
    "**Data**: 1,950 executions from August 2025 to February 2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"✓ Imports loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data from S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lambda_logs():\n",
    "    \"\"\"Load all Lambda logs from S3 into a pandas DataFrame.\"\"\"\n",
    "    s3 = boto3.client('s3', region_name='eu-west-1')\n",
    "    bucket = 'gardencam-berrylands-eu-west-1'\n",
    "    prefix = 'lambda-logs-athena/'\n",
    "    \n",
    "    # List all JSON files\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n",
    "    \n",
    "    all_logs = []\n",
    "    \n",
    "    for page in pages:\n",
    "        if 'Contents' not in page:\n",
    "            continue\n",
    "            \n",
    "        for obj in page['Contents']:\n",
    "            key = obj['Key']\n",
    "            \n",
    "            # Skip directories\n",
    "            if not key.endswith('.json'):\n",
    "                continue\n",
    "            \n",
    "            # Read file\n",
    "            response = s3.get_object(Bucket=bucket, Key=key)\n",
    "            content = response['Body'].read().decode('utf-8')\n",
    "            \n",
    "            # Parse newline-delimited JSON\n",
    "            for line in content.strip().split('\\n'):\n",
    "                if line:\n",
    "                    all_logs.append(json.loads(line))\n",
    "    \n",
    "    print(f\"✓ Loaded {len(all_logs):,} logs from S3\")\n",
    "    return pd.DataFrame(all_logs)\n",
    "\n",
    "# Load data\n",
    "df = load_lambda_logs()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert timestamp to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Convert costs to microdollars\n",
    "df['cost_microdollars'] = df['estimated_cost_usd'] * 1_000_000\n",
    "\n",
    "# Sort by timestamp\n",
    "df = df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "print(f\"Data range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"Total executions: {len(df):,}\")\n",
    "print(f\"Total cost: {df['cost_microdollars'].sum():.2f} µ$\")\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "df[['duration_ms', 'memory_limit_mb', 'cost_microdollars']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requests by path\n",
    "path_counts = df['path'].value_counts()\n",
    "print(\"\\nTop 10 endpoints by request count:\")\n",
    "print(path_counts.head(10))\n",
    "\n",
    "# Percentage breakdown\n",
    "print(\"\\nPercentage breakdown:\")\n",
    "print((path_counts / len(df) * 100).head(10).round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily request counts\n",
    "daily = df.groupby(df['timestamp'].dt.date).agg({\n",
    "    'request_id': 'count',\n",
    "    'duration_ms': 'mean',\n",
    "    'cost_microdollars': 'sum'\n",
    "}).rename(columns={'request_id': 'count'})\n",
    "\n",
    "# Plot daily requests\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "# Request count\n",
    "daily['count'].plot(ax=ax1, linewidth=2, color='#4a9eff')\n",
    "ax1.set_title('Daily Request Count', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Requests', fontsize=12)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Cost\n",
    "daily['cost_microdollars'].plot(ax=ax2, linewidth=2, color='#32cd32')\n",
    "ax2.set_title('Daily Cost (Microdollars)', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Cost (µ$)', fontsize=12)\n",
    "ax2.set_xlabel('Date', fontsize=12)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nPeak day: {daily['count'].idxmax()} with {daily['count'].max()} requests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Path Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top paths pie chart\n",
    "top_paths = df['path'].value_counts().head(10)\n",
    "\n",
    "fig = px.pie(\n",
    "    values=top_paths.values,\n",
    "    names=top_paths.index,\n",
    "    title='Top 10 Endpoints by Request Count',\n",
    "    hole=0.3\n",
    ")\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path performance comparison\n",
    "path_stats = df.groupby('path').agg({\n",
    "    'request_id': 'count',\n",
    "    'duration_ms': 'mean',\n",
    "    'cost_microdollars': 'sum'\n",
    "}).rename(columns={'request_id': 'count'})\n",
    "\n",
    "path_stats = path_stats.sort_values('count', ascending=False).head(10)\n",
    "\n",
    "print(\"Top 10 paths by request count:\")\n",
    "print(path_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Duration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "df['duration_ms'].hist(bins=50, ax=ax1, color='#6a5acd', alpha=0.7)\n",
    "ax1.set_title('Duration Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('Duration (ms)', fontsize=12)\n",
    "ax1.set_ylabel('Frequency', fontsize=12)\n",
    "ax1.axvline(df['duration_ms'].mean(), color='red', linestyle='--', label=f'Mean: {df[\"duration_ms\"].mean():.0f}ms')\n",
    "ax1.axvline(df['duration_ms'].median(), color='green', linestyle='--', label=f'Median: {df[\"duration_ms\"].median():.0f}ms')\n",
    "ax1.legend()\n",
    "\n",
    "# Box plot by path (top 5 paths)\n",
    "top_5_paths = df['path'].value_counts().head(5).index\n",
    "df[df['path'].isin(top_5_paths)].boxplot(column='duration_ms', by='path', ax=ax2)\n",
    "ax2.set_title('Duration by Top 5 Paths', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('Path', fontsize=12)\n",
    "ax2.set_ylabel('Duration (ms)', fontsize=12)\n",
    "plt.suptitle('')  # Remove default title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly cost breakdown\n",
    "monthly = df.groupby(df['timestamp'].dt.to_period('M')).agg({\n",
    "    'request_id': 'count',\n",
    "    'cost_microdollars': 'sum'\n",
    "}).rename(columns={'request_id': 'requests'})\n",
    "\n",
    "print(\"Monthly breakdown:\")\n",
    "print(monthly)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "monthly['cost_microdollars'].plot(kind='bar', ax=ax, color='#32cd32')\n",
    "ax.set_title('Monthly Cost (Microdollars)', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Cost (µ$)', fontsize=12)\n",
    "ax.set_xlabel('Month', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTotal cost across all months: {monthly['cost_microdollars'].sum():.2f} µ$\")\n",
    "print(f\"Average monthly cost: {monthly['cost_microdollars'].mean():.2f} µ$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Time Series (Plotly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hourly aggregation for smoother chart\n",
    "hourly = df.set_index('timestamp').resample('H').agg({\n",
    "    'request_id': 'count',\n",
    "    'duration_ms': 'mean',\n",
    "    'cost_microdollars': 'sum'\n",
    "}).rename(columns={'request_id': 'count'})\n",
    "\n",
    "# Interactive plot\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=hourly.index,\n",
    "    y=hourly['count'],\n",
    "    mode='lines',\n",
    "    name='Request Count',\n",
    "    line=dict(color='#4a9eff', width=2),\n",
    "    fill='tozeroy',\n",
    "    fillcolor='rgba(74, 158, 255, 0.2)'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Request Count Over Time (Hourly)',\n",
    "    xaxis_title='Time',\n",
    "    yaxis_title='Requests',\n",
    "    hovermode='x unified',\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Custom Analysis\n",
    "\n",
    "Use this section for your own explorations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Find the January spike\n",
    "jan_spike = df[(df['timestamp'] >= '2026-01-19') & (df['timestamp'] <= '2026-01-27')]\n",
    "\n",
    "print(f\"January spike (Jan 19-27):\")\n",
    "print(f\"Total requests: {len(jan_spike):,}\")\n",
    "print(f\"Daily average: {len(jan_spike)/9:.0f}\")\n",
    "print(f\"\\nPath breakdown:\")\n",
    "print(jan_spike['path'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your analysis here...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export summary to CSV\n",
    "daily.to_csv('/home/tot/cv/daily_summary.csv')\n",
    "print(\"✓ Exported daily summary to daily_summary.csv\")\n",
    "\n",
    "# Export full dataset\n",
    "df.to_csv('/home/tot/cv/lambda_logs_full.csv', index=False)\n",
    "print(\"✓ Exported full dataset to lambda_logs_full.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
